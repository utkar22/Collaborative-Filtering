{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNhVG194YBBw",
        "outputId": "d6b14ee2-2297-4575-8fc7-125d4f3f062f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-30 19:20:28--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4924029 (4.7M) [application/zip]\n",
            "Saving to: ‘ml-100k.zip.1’\n",
            "\n",
            "ml-100k.zip.1       100%[===================>]   4.70M  16.8MB/s    in 0.3s    \n",
            "\n",
            "2023-03-30 19:20:29 (16.8 MB/s) - ‘ml-100k.zip.1’ saved [4924029/4924029]\n",
            "\n",
            "Archive:  ml-100k.zip\n",
            "replace ml-100k/allbut.pl? [y]es, [n]o, [A]ll, [N]one, [r]ename: no\n",
            "replace ml-100k/mku.sh? [y]es, [n]o, [A]ll, [N]one, [r]ename: none\n",
            "replace ml-100k/README? [y]es, [n]o, [A]ll, [N]one, [r]ename: no\n",
            "replace ml-100k/u.data? [y]es, [n]o, [A]ll, [N]one, [r]ename: no\n",
            "replace ml-100k/u.genre? [y]es, [n]o, [A]ll, [N]one, [r]ename: no\n",
            "replace ml-100k/u.info? [y]es, [n]o, [A]ll, [N]one, [r]ename: no\n",
            "replace ml-100k/u.item? [y]es, [n]o, [A]ll, [N]one, [r]ename: no\n",
            "replace ml-100k/u.occupation? [y]es, [n]o, [A]ll, [N]one, [r]ename: no\n",
            "replace ml-100k/u.user? [y]es, [n]o, [A]ll, [N]one, [r]ename: no\n",
            "replace ml-100k/u1.base? [y]es, [n]o, [A]ll, [N]one, [r]ename: no\n",
            "replace ml-100k/u1.test? [y]es, [n]o, [A]ll, [N]one, [r]ename: no\n",
            "replace ml-100k/u2.base? [y]es, [n]o, [A]ll, [N]one, [r]ename: no\n",
            "replace ml-100k/u2.test? [y]es, [n]o, [A]ll, [N]one, [r]ename: no\n",
            "replace ml-100k/u3.base? [y]es, [n]o, [A]ll, [N]one, [r]ename: no\n",
            "replace ml-100k/u3.test? [y]es, [n]o, [A]ll, [N]one, [r]ename: no\n",
            "replace ml-100k/u4.base? [y]es, [n]o, [A]ll, [N]one, [r]ename: no\n",
            "replace ml-100k/u4.test? [y]es, [n]o, [A]ll, [N]one, [r]ename: no\n",
            "replace ml-100k/u5.base? [y]es, [n]o, [A]ll, [N]one, [r]ename: no\n",
            "replace ml-100k/u5.test? [y]es, [n]o, [A]ll, [N]one, [r]ename: no\n",
            "replace ml-100k/ua.base? [y]es, [n]o, [A]ll, [N]one, [r]ename: no\n",
            "replace ml-100k/ua.test? [y]es, [n]o, [A]ll, [N]one, [r]ename: no\n",
            "replace ml-100k/ub.base? [y]es, [n]o, [A]ll, [N]one, [r]ename: no\n",
            "replace ml-100k/ub.test? [y]es, [n]o, [A]ll, [N]one, [r]ename: no\n"
          ]
        }
      ],
      "source": [
        "!wget http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
        "!unzip ml-100k.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import math\n",
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "VFm-FSUaYIYg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "def calculate_mean_absolute_error(y_pred, y_true):\n",
        "    # Select only the elements of y_pred and y_true that correspond to non-zero elements of y_true\n",
        "    non_zero_indices = y_true.nonzero()\n",
        "    y_pred_non_zero = y_pred[non_zero_indices]\n",
        "    y_true_non_zero = y_true[non_zero_indices]\n",
        "    \n",
        "    # Calculate and return the mean absolute error between the predicted and true values\n",
        "    mae = mean_absolute_error(y_pred_non_zero, y_true_non_zero)\n",
        "    return mae"
      ],
      "metadata": {
        "id": "hI3cBsqDQZ8J"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_rating = 5\n",
        "min_rating = 1\n",
        "normal = max_rating - min_rating"
      ],
      "metadata": {
        "id": "5odYa9Jy9aGK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalise(ratings):\n",
        "    min_ratings = []\n",
        "    max_ratings = []\n",
        "\n",
        "    for i in ratings:\n",
        "        min_r = 5\n",
        "        max_r = 1\n",
        "        for j in i:\n",
        "            if j!=0:\n",
        "                if j>max_r:\n",
        "                    max_r=j\n",
        "                if j<min_r:\n",
        "                    min_r=j\n",
        "        min_ratings.append(min_r)\n",
        "        max_ratings.append(max_r)\n",
        "\n",
        "    for i in range(len(ratings)):\n",
        "        min_r = min_ratings[i]\n",
        "        max_r = max_ratings[i]\n",
        "        for j in range(len(ratings[i])):\n",
        "            if (ratings[i][j]!=0):\n",
        "                if (min_r!=max_r):\n",
        "                    ratings[i][j] = (ratings[i][j] - min_r)#/(max_r - min_r)\n",
        "\n",
        "    return ratings\n",
        "\n"
      ],
      "metadata": {
        "id": "Ajbxruc0naU3"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(user_vecs, item_vecs):\n",
        "    preds = np.zeros((user_vecs.shape[0], item_vecs.shape[0]))\n",
        "    u = 0\n",
        "    while u < user_vecs.shape[0]:\n",
        "        i = 0\n",
        "        while i < item_vecs.shape[0]:\n",
        "            preds[u, i] = user_vecs[u, :].dot(item_vecs[i, :].T)\n",
        "            i += 1\n",
        "        u += 1\n",
        "    return preds\n",
        "\n",
        "def ALS(lat_vectors, fixed_vecs, ratings, mu, how):\n",
        "\n",
        "    A = fixed_vecs.T.dot(fixed_vecs)\n",
        "    muI = np.eye(A.shape[0]) * mu\n",
        "\n",
        "    B = A+muI\n",
        "\n",
        "    shp = lat_vectors.shape[0]\n",
        "    \n",
        "    if how == 'user':\n",
        "        u = 0\n",
        "        while u < shp:\n",
        "            lat_vectors[u, :] = np.linalg.solve(B, ratings[u, :].dot(fixed_vecs))\n",
        "            u += 1\n",
        "    elif how == 'item':    \n",
        "        i = 0\n",
        "        while i < shp:\n",
        "            lat_vectors[i, :] = np.linalg.solve(B, ratings[:, i].T.dot(fixed_vecs))\n",
        "            i += 1\n",
        "    \n",
        "    return lat_vectors\n",
        "\n",
        "\n",
        "\n",
        "def partial_train(iter_count, user_vecs, item_vecs, ratings, user_reg, item_reg):\n",
        "    \n",
        "    i = 0\n",
        "    while i < iter_count:\n",
        "        user_vecs = ALS(user_vecs, item_vecs, ratings, user_reg, 'user')\n",
        "        item_vecs = ALS(item_vecs, user_vecs, ratings, item_reg, 'item')\n",
        "        i += 1\n",
        "    \n",
        "    return user_vecs, item_vecs\n",
        "\n",
        "\n",
        "\n",
        "def train(iter_count, ratings, factor_count, user_reg, item_reg):\n",
        "    \"\"\" Train model for iter_count iterations from scratch.\"\"\"\n",
        "    # initialize latent vectors\n",
        "    n_users, n_items = ratings.shape\n",
        "\n",
        "    user_vecs = np.random.random((n_users, factor_count))\n",
        "    item_vecs = np.random.random((n_items, factor_count))\n",
        "    \n",
        "    user_vecs, item_vecs = partial_train(iter_count, user_vecs, item_vecs, ratings, user_reg, item_reg)\n",
        "    return user_vecs, item_vecs\n",
        "\n",
        "\n",
        "def find_mae(iter_arr, rating_test, rating_train, factor_count, user_reg, item_reg):\n",
        "    iter_arr.sort()\n",
        "    train_mae =[]\n",
        "    test_mae = []\n",
        "    iter_diff = 0\n",
        "\n",
        "    i = 0\n",
        "    user_vecs, item_vecs = train(iter_arr[i] - iter_diff, rating_train, factor_count, user_reg, item_reg)\n",
        "\n",
        "    while i < len(iter_arr):\n",
        "        preds = predict(user_vecs, item_vecs)\n",
        "        train_mae.append(calculate_mean_absolute_error(preds, rating_train))\n",
        "        test_mae.append(calculate_mean_absolute_error(preds, rating_test))\n",
        "\n",
        "        if i < len(iter_arr) - 1:\n",
        "            iter_diff = iter_arr[i+1] - iter_arr[i]\n",
        "            user_vecs, item_vecs = partial_train(iter_diff, user_vecs, item_vecs, rating_train, user_reg, item_reg)\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    return (min(train_mae) / normal , min(test_mae) / normal)\n"
      ],
      "metadata": {
        "id": "j5aRG4XLuPxT"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iter_arr = [1,]\n",
        "iter_arr.append(2)\n",
        "iter_arr.append(5)\n",
        "iter_arr.append(10)\n",
        "\n",
        "reg_arr = [0.1, 1, 10]\n",
        "LF = [5, 10, 20]\n",
        "\n",
        "total_folds = 5\n",
        "curr_fold = 1\n",
        "\n",
        "train_nmae_arr = []\n",
        "test_nmae_arr = []\n",
        "\n",
        "while (curr_fold<=total_folds):\n",
        "    print(f\"Fold {curr_fold}\")\n",
        "\n",
        "    train_file = open(f\"ml-100k/u{curr_fold}.base\",\"r\")\n",
        "    test_file = open(f\"ml-100k/u{curr_fold}.test\",\"r\")\n",
        "\n",
        "    train_lines = train_file.readlines()\n",
        "    test_lines = test_file.readlines()\n",
        "\n",
        "    train_file.close()\n",
        "    test_file.close()\n",
        "\n",
        "    user_count = 943\n",
        "    item_count = 1682\n",
        "\n",
        "    table_train = [[0 for x in range(item_count+1)] for y in range(user_count+1)]\n",
        "    table_test = [[0 for x in range(item_count+1)] for y in range(user_count+1)]\n",
        "    \n",
        "\n",
        "    for line in train_lines:\n",
        "        splitted = line.split()\n",
        "        user_s = int(splitted[0])\n",
        "        item_s = int(splitted[1])\n",
        "        rating = int(splitted[2])/5\n",
        "        table_train[user_s][item_s] = rating\n",
        "\n",
        "    for line in test_lines:\n",
        "        splitted = line.split()\n",
        "        user_s = int(splitted[0])\n",
        "        item_s = int(splitted[1])\n",
        "        rating = int(splitted[2])\n",
        "        table_test[user_s][item_s] = rating\n",
        "\n",
        "    table_train = normalise(table_train)\n",
        "    table_test = normalise(table_test)\n",
        "\n",
        "    np_train = np.array(table_train)\n",
        "    np_test = np.array(table_test)\n",
        "\n",
        "\n",
        "    min_train_nmae = 100\n",
        "    min_test_nmae = 100\n",
        "\n",
        "    i = 0\n",
        "    while i < len(LF):\n",
        "        j = 0\n",
        "        while j < len(reg_arr):\n",
        "\n",
        "            nmae = find_mae(iter_arr=iter_arr, rating_test=np_test, rating_train=np_train, factor_count=LF[i], user_reg=reg_arr[j], item_reg=reg_arr[j])\n",
        "            if (nmae and nmae[0] < min_train_nmae):\n",
        "                min_train_nmae = nmae[0]\n",
        "            if (nmae and nmae[1] < min_test_nmae):\n",
        "                min_test_nmae = nmae[1]\n",
        "\n",
        "            j += 1\n",
        "        i += 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #print(f\"Train nmae: {min_train_nmae}\")\n",
        "    print(f\"Test nmae: {min_test_nmae}\")\n",
        "    print()\n",
        "\n",
        "    train_nmae_arr.append(min_train_nmae)\n",
        "    test_nmae_arr.append(min_test_nmae)\n",
        "\n",
        "\n",
        "    curr_fold+=1\n",
        "\n",
        "avg_train = 0\n",
        "avg_test = 0\n",
        "for i in range(total_folds):\n",
        "    avg_train += train_nmae_arr[i]\n",
        "    avg_test += test_nmae_arr[i]\n",
        "\n",
        "avg_train = avg_train/total_folds\n",
        "avg_test = avg_test/total_folds\n",
        "\n",
        "print(f\"Average test nmae: {avg_test}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4j5DMJZKRRb7",
        "outputId": "39e73acd-b474-432a-89b6-f854bb36a208"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1\n",
            "Test nmae: 0.5935295776335711\n",
            "\n",
            "Fold 2\n",
            "Test nmae: 0.5743936899777906\n",
            "\n",
            "Fold 3\n",
            "Test nmae: 0.5479957441310971\n",
            "\n",
            "Fold 4\n",
            "Test nmae: 0.5446331456434517\n",
            "\n",
            "Fold 5\n",
            "Test nmae: 0.5617261492104729\n",
            "\n",
            "Average test nmae: 0.5644556613192766\n"
          ]
        }
      ]
    }
  ]
}